{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb314e7e-e5c3-4842-903c-e405dd02612f",
   "metadata": {},
   "source": [
    "# Regresion logistica: tipo de trafico en la darknet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c799726-e9fa-4fd5-83fb-ec427f423912",
   "metadata": {},
   "source": [
    "Se construye un sistema capas de predecir el tipo de trafico dentro de la darknet utilizando las caracteristicas de flujo de datos, como los puertos de origen y destino, el protocolo, la duración del flujo, el número de paquetes, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70ebdb7-6780-48db-bb43-1405c0d065d3",
   "metadata": {},
   "source": [
    "## Importacion de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fced69f7-17e0-4a4b-a1e6-eb651bf39436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas necesarias\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fd7b7c-4342-4f57-97be-8c3bad8cbc2c",
   "metadata": {},
   "source": [
    "##  Carga y vista inicial de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "047484af-7009-4400-b79c-73f01903ac21",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Cargar el dataset\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marchivos\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDarknet.CSV\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Ver las primeras filas del dataset\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar el dataset\n",
    "df = pd.read_csv(os.path.join('archivos', 'Darknet.CSV'))\n",
    "\n",
    "# Ver las primeras filas del dataset\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9d6d5a-421a-498a-bffa-1e1ba0e6baa4",
   "metadata": {},
   "source": [
    "## Preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1537274d-4428-4d08-8e2d-dc0735a38595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selección de columnas (usamos todas las numéricas y 'Label' como objetivo)\n",
    "X = df.drop(columns=['Label', 'Label.1', 'Flow ID', 'Src IP', 'Dst IP', 'Timestamp'])  # Eliminamos columnas no numéricas\n",
    "y = df['Label']  # Etiqueta objetivo\n",
    "\n",
    "# Convertir las etiquetas de texto a valores numéricos (si 'Label' es texto)\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bed9076-4108-4eec-97dd-391f3627fcc1",
   "metadata": {},
   "source": [
    "## División del conjunto de datos en entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c47c1b2-40fa-47b3-97c2-c3e3dbe075ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir el dataset en entrenamiento y prueba (80% entrenamiento, 20% prueba)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4071fe4-7045-4897-bc6d-42543b7f8f12",
   "metadata": {},
   "source": [
    "## Limpieza de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796765cf-2ad1-4d1f-9ec0-4f75bc1d8518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar valores infinitos por NaN en X_train y X_test\n",
    "X_train.replace([float('inf'), -float('inf')], np.nan, inplace=True)\n",
    "X_test.replace([float('inf'), -float('inf')], np.nan, inplace=True)\n",
    "\n",
    "# Rellenar los valores NaN con la media de cada columna en X_train y X_test\n",
    "X_train.fillna(X_train.mean(), inplace=True)\n",
    "X_test.fillna(X_test.mean(), inplace=True)\n",
    "\n",
    "# Verificar si hay valores extremadamente grandes y reemplazarlos\n",
    "max_value = 1e10\n",
    "X_train[X_train > max_value] = max_value\n",
    "X_test[X_test > max_value] = max_value\n",
    "\n",
    "# Verificar la desviación estándar de cada columna\n",
    "std_devs = X_train.std()\n",
    "\n",
    "# Identificar las columnas con desviación estándar cero\n",
    "zero_std_columns = std_devs[std_devs == 0].index\n",
    "\n",
    "# Eliminar columnas con desviación estándar cero\n",
    "X_train = X_train.drop(columns=zero_std_columns)\n",
    "X_test = X_test.drop(columns=zero_std_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6d900b-ea31-41b2-ac09-6ebce9d3d9fc",
   "metadata": {},
   "source": [
    "## Escalado de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bae130-7bb0-4216-babb-96d83d48831d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalar los datos después de la limpieza\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e15ceb0-297c-4ee8-8182-d922d5abba50",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo de regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875d89ba-cfc8-4fb4-9265-5700e7cd6351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el modelo de regresión logística\n",
    "log_reg = LogisticRegression(max_iter=50000)\n",
    "\n",
    "# Entrenar el modelo\n",
    "log_reg.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1693a8-6cd2-4c9e-b880-0d37e6d3249b",
   "metadata": {},
   "source": [
    "## Evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "331b24c5-15c4-43ab-9eca-a0e37539cae3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'log_reg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Hacer predicciones\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m log_reg\u001b[38;5;241m.\u001b[39mpredict(X_test_scaled)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Evaluar el modelo utilizando la precisión\u001b[39;00m\n\u001b[1;32m      5\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'log_reg' is not defined"
     ]
    }
   ],
   "source": [
    "# Hacer predicciones\n",
    "y_pred = log_reg.predict(X_test_scaled)\n",
    "\n",
    "# Evaluar el modelo utilizando la precisión\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c77c3fe-76e2-4138-ae54-ff9e87db9b4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Matriz de confusión\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(y_test, y_pred)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatriz de Confusión:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(cm)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "# Matriz de confusión\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42f72616-29bc-482a-bda7-65ddf474b651",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Calcular la matriz de confusión\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(y_test, y_pred)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Crear un mapa de calor de la matriz de confusión\u001b[39;00m\n\u001b[1;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Crear un mapa de calor de la matriz de confusión\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d598322e-85e9-4c80-b765-565f8f474666",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Binarizar las etiquetas para multiclase\n",
    "y_test_bin = label_binarize(y_test, classes=label_encoder.classes_)\n",
    "y_pred_bin = label_binarize(y_pred, classes=label_encoder.classes_)\n",
    "\n",
    "# Calcular la curva ROC y el AUC para cada clase\n",
    "fpr, tpr, _ = roc_curve(y_test_bin[:, 0], y_pred_bin[:, 0])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Graficar la curva ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='Curva ROC (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Tasa de falsos positivos')\n",
    "plt.ylabel('Tasa de verdaderos positivos')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb6a631-1e1d-47a0-9a3d-8eec5c2eadb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Comparar predicciones y etiquetas reales\n",
    "labels = label_encoder.classes_\n",
    "real_counts = np.bincount(y_test)\n",
    "pred_counts = np.bincount(y_pred)\n",
    "\n",
    "# Crear un gráfico de barras\n",
    "x = np.arange(len(labels))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "rects1 = ax.bar(x - width/2, real_counts, width, label='Real')\n",
    "rects2 = ax.bar(x + width/2, pred_counts, width, label='Predicción')\n",
    "\n",
    "ax.set_xlabel('Clase')\n",
    "ax.set_ylabel('Cantidad')\n",
    "ax.set_title('Comparación entre etiquetas reales y predicciones')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels, rotation=45)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
